BAYESIAN OPTIMIZATION
Report by
THOMAS JAMES
In Partial Fulfillment of the Requirements
for the Degree Of
MSc in Computer Science
Dr. Sinnu Susan Thomas
School of Computer Science and Engineering
KERALA UNIVERSITY OF DIGITAL SCIENCES, INNOV ATION AND
TECHNOLOGY
9 January 2024Abstract
Bayesian optimization is a technique used to find the maximum of functions which are costly to evaluate. It
applies Bayesian principles by initially making an educated guess known as prior about the objective function
and then updating this guess with observed data to form a more accurate prediction (posterior). This allows for
an excellent selection of where to gather the following information from the function. In order to do that, it is
essential to strike a balance between exploring areas of high uncertainty (exploration) and focusing on areas that
are likely to yield better results than what we currently have (exploitation) and these functions help us to strike
a balance between exploration and exploitation is known as acquisition functions. These acquisition functions
must be maximized to find the data point, which must be augmented onto the prior knowledge. Thereby giving
a more accurate estimate of the black box function.
While Bayesian Optimization typically limits parameter space exploration to sequential processes, there is
often a desire to concurrently propose batches of parameter values, particularly in the presence of large parallel
processing capabilities. However, implementing batch methods requires modeling the interaction among eval-
uations within the batch, which can be costly in complex scenarios. In addressing this challenge, a highly ef-
fective heuristic is introduced on an estimate of the function’s Lipschitz constant, focusing on the crucial aspect
of local repulsion, with minimal computational overhead. To facilitate simultaneous exploration,a penalized
acquisition function to gather batches of points, aiming to minimize non-parallelizable computational effort.
The resulting algorithm exhibits impressive runtime performance, comparing favorably with more intricate al-
ternatives. Batch Bayesian Optimization introduces a promising solution for efficient parameter exploration,
particularly valuable in scenarios with substantial parallel processing resources.Acknowledgement
I want to express my sincere gratitude to Dr. Sinnu Susan Thomas for her invaluable support and guidance
throughout this endeavor. Her mentorship has been a guiding light in my journey. I am also profoundly thankful
to the Kerala University of Digital Sciences and Innovation Technology for allowing me to work under her
supervision for one month.
I would also like to thank Sumesh Sir for his unwavering support and assistance during my time at the
workspace in KABANI.Certificate
This is to certify that the report Bayesian Optimization submitted by Thomas James (Reg. No: 221120)
in partial fulfillment of the requirements for the award of MSc Degree in Computer Science is a bonafide
record of the work carried out at Kerala University of Digital Sciences, Innovation and Technology under
my supervision.
Supervisor
Dr. Sinnu Susan Thomas
Assistant ProfessorContents
List of Figures ix
1 Introduction 1
1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Bayesian Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.3 Batch Bayesian Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.4 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.5 Organization of the Report . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
2 Literature Review 5
2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2.2 State-of-the-art Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2.2.1 Bayesian Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2.2.1.1 Batch Bayesian optimization . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
3 Methodology 7
3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
3.2 Working Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
3.2.1 Restrictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.3 Bayesian Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.3.1 Gaussian Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.3.1.1 Choice Of Covariance Function . . . . . . . . . . . . . . . . . . . . . . . . 9
3.3.2 Acquisition Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.3.2.1 Probability of improvement . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.3.2.2 Expected Improvement . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.3.2.3 Knowledge Gradient . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
vii3.3.2.4 Upper Confidence Bound . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
3.3.2.5 Lipschitzian Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
3.4 Batch Bayesain Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
3.4.1 Local Penalizer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
3.4.1.1 Choosing Local Penalizers . . . . . . . . . . . . . . . . . . . . . . . . . . 14
3.4.2 Selecting Lipschitzian Constant ( L) and Maxima ( M) . . . . . . . . . . . . . . . . . 15
3.5 Augmenting the Datapoints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
3.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
4 Results and Discussions 17
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
4.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
4.2.1 Bayesian Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
4.2.1.1 Gaussian Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
4.2.1.2 Gaussian Process using Different Lengthscales . . . . . . . . . . . . . . . . 18
4.2.1.3 Acquisition Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
4.2.1.4 Bayesian Optimization illustration . . . . . . . . . . . . . . . . . . . . . . 19
4.2.2 Batch Bayesian Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
4.2.3 Maximum Probability Of Improvement . . . . . . . . . . . . . . . . . . . . . . . . . 20
4.2.3.1 Local Penalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
4.2.3.2 Without Local Penalization . . . . . . . . . . . . . . . . . . . . . . . . . . 20
4.2.4 Expectation Improvement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
4.2.4.1 Local Penalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
4.2.4.2 Without Local Penalization . . . . . . . . . . . . . . . . . . . . . . . . . . 21
4.2.5 Convergence Plot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
4.2.5.1 Maximum Probability of Improvement . . . . . . . . . . . . . . . . . . . . 22
4.2.5.2 Expectation Improvement . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
4.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
5 Conclusions and Future Work 25
5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
5.2 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
5.3 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
References 27
viiiList of Figures
3.1 The region of probable improvement. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
3.2 Computing the Lipschitzian bound for an interval [1] . . . . . . . . . . . . . . . . . . . . . . 13
4.1 Gaussian Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
4.2 Effect of different Lengthscales using a Gaussian Process . . . . . . . . . . . . . . . . . . . . 18
4.3 Probability Of Improvement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
4.4 Expected Improvement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
4.5 Upper Confidence Bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
4.6 Bayesian Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
4.7 Maximum Probability of Improvement via Local Penalization . . . . . . . . . . . . . . . . . 21
4.8 Maximum Probability of Improvement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
4.9 Expectation Improvement via Local Penalization . . . . . . . . . . . . . . . . . . . . . . . . 22
4.10 Expectation Improvement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
4.11 Convergence plot of MPI with Local Penalization . . . . . . . . . . . . . . . . . . . . . . . . 23
4.12 Convergence plot of MPI without Local Penalization . . . . . . . . . . . . . . . . . . . . . . 23
4.13 Comparison of Convergence Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
4.14 Convergence plot of EI with Local Penalization . . . . . . . . . . . . . . . . . . . . . . . . . 23
4.15 Convergence plot of EI without Local Penalization . . . . . . . . . . . . . . . . . . . . . . . 23
4.16 Comparison of Convergence Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
ixChapter 1
Introduction
1.1 Introduction
In many scientific and industrial fields, finding the best solutions for complex problems is difficult. Whether
in artificial intelligence, data mining, bioinformatics, software engineering, scheduling, manufacturing, or eco-
nomics, the quest for optimal outcomes is a constant challenge. Often, these problems are tricky because they
lack explicit mathematical formulas, are costly to analyze, and we may need to learn how steep or smooth
their curves are. Traditional optimization methods, like evolutionary algorithms, have solved these challenges.
However, they often require many evaluations, which means they take up significant time and resources. That is
where Bayesian optimization comes in as a valuable and efficient strategy to tackle these complex optimization
problems. What makes Bayesian optimization stand out is its ability to work with limited data and make use of
existing knowledge.
1.2 Bayesian Optimization
Bayesian Optimization tries to optimize the black box functions by initially guessing what the objective
function might look like. Then, it combines this guess with the information it gathers from observations to
update its understanding. This allows it to decide where to look next in the search space. Importantly, this
decision-making process balances two essential aspects: exploration and exploitation. Exploration involves
checking out uncertain areas, while exploitation involves focusing on places likely to improve upon the best
observation.
The real strength of Bayesian optimization becomes evident while dealing with functions that are expensive
to test and cannot be neatly described with equations. It is a valuable tool when data points can only be obtained
by testing without a clear formula. Thus, this is useful when the evaluations are resource-intensive.2 Introduction
1.3 Batch Bayesian Optimization
Batch Bayesian optimization uses multiple configurations simultaneously, especially with the computa-
tional capabilities of modern system. It estimates how rapidly the function changes around a point, known
as the Lipschitz constant, without incurring excessive computational costs. This allows for the simultaneous
exploration of various configurations. To make this process efficient, it employs a specialized method for se-
lecting points, referred to as a penalized acquisition function. This enhances the speed of the exploration, even
when dealing with multiple configurations at once.
1.4 Motivation
Assessing the objective function can be time-consuming and resource-intensive in many practical situa-
tions. Bayesian Optimization tackles this challenge by smartly picking evaluation points that provide valuable
insights. This approach significantly reduces the number of evaluations required to find the best solution. Un-
like traditional optimization methods, which can get stuck in local optima, Bayesian Optimization offers a
probabilistic framework that thoroughly explores the entire search space. This boosts the chances of discov-
ering the global best solution, making it a robust choice for complex optimization tasks. Another remarkable
advantage of Bayesian Optimization is its capacity to quantify uncertainty in the predictions of the objective
function. This capability is crucial for making well-informed decisions, as it offers a clear understanding of the
uncertainty associated with different choices.
Batch Bayesian optimization is driven by a practical need to speed up the optimization process inorder
to evaluate multiple points in a function at the same time. Traditional methods usually look at one point at
a time, going through the parameter space step by step. However, in today’s computing environments, the
ability to run multiple evaluations concurrently, either in terms of using computational resources or conducting
physical experiments are available. Batch Bayesian optimization aims to take advantage of this capability by
considering several points at once in each optimization step, thereby making the whole process faster. This is
particularly beneficial when evaluating the function is expensive, like in simulations or real-world experiments.
The main idea is to use resources more efficiently, decrease the total time needed for optimization, and explore
different parts of the parameter space simultaneously for a more comprehensive understanding.
1.5 Organization of the Report
The report is organized into five main chapters, each serving a specific purpose within the study. Chapter 2
delves into the literature review, providing a comprehensive overview by referencing relevant research papers
that have significantly contributed to shaping the study’s foundation. Moving on to Chapter 3, a detailed1.5 Organization of the Report 3
exploration of the Bayesian Optimization methodology is presented, offering a clear explanation of the essential
steps and concepts involved in the process.
Chapter 4 shifts the focus to presenting the results obtained from practical Python coding experiments.
Finally, Chapter 5 marks the conclusion of the report and a look towards the future. It summarizes the study’s
findings and outlines potential future research and exploration directions in this dynamic field.
.Chapter 2
Literature Review
2.1 Introduction
The preceding section provided a concise introduction to Bayesian Optimization. In this chapter, we delve
into the origins of these concepts, offering insights into how these ideas were initially developed and formu-
lated. This exploration provides a historical context and sheds light on the evolution of Bayesian Optimization
as a robust methodology in the optimization field.
2.2 State-of-the-art Approaches
2.2.1 Bayesian Optimization
In Bayesian optimization, a Gaussian process is employed as the surrogate model, fine-tuned by maximizing
likelihood, which was first introduced into the realm of machine learning [2]. Notably, recent developments
have given rise to several Kriging variants, expanding the surrogate modeling techniques.
The origin of Bayesian optimization’s Acquisition function can be dated back to work in 1962 [3] and 1964
[4], where Wiener processes were adopted for unconstrained one-dimensional optimization problems. The
probability of improvement is maximized by selecting the following sample. Mockus developed a new acqui-
sition function called expectation of improvement (EI) [5]. An idea closely related to EI is the Knowledge
Gradient (KG) [6], maximizing the expected incremental value of a measurement; which does not depend on
the optimum obtained so far. Then the confidence bound criteria, upper confidence bound (UCB) [7] for max-
imization problems and lower confidence bound (LCB) for minimization problems, were designed to achieve
optimal regret in the multi-armed bandit community by combining the uncertainty and the expected reward.
Global optimization techniques were established based on the assumption that it follows the Lipschitzian
[1] condition, and based upon that knowledge, various algorithms like Shubert’s algorithm [8] and DIRECT6 Literature Review
algorithm were introduced so that the global optimum could easily be found out in a restricted environment.
2.2.1.1 Batch Bayesian optimization
The preceding section details the methodology for addressing the standard Bayesian optimization problem,
specifically focusing on black-box single-objective optimization. This section provides an overview of con-
temporary Bayesian optimization algorithms, highlighting significant advancements such as Meta Learning,
Multi-Task Learning, Multi-Objective Learning, and Multi-Task Learning
Meta Learning [9],introduces a paradigm where models evolve to become adept learners. Meta Learning,
akin to a seasoned guide, imparts the ability to adapt and thrive across various optimization environments.Multi-
Task Learning [10] and Swersky et al. [11], collaborates task and shares knowledge to enrich the optimization
procedure. Multi-Objective Learning [12], introduces the art of handling multiple goals at same time, where
the optimization gains complexity and depth.
Batch Bayesian Optimization via Local Penalization: From these advancements, a unique methodology
was found in common. The core idea was Batch Bayesian Optimization via Local Penalization, a distinctive
approach detailed in Section 3. Here, the challenges demand simultaneous exploration of multiple points, and
a clever strategy emerges. Local penalizers shape the exploration landscape, guided by the belief in proximity
to global maxima.
2.3 Summary
This chapter is dedicated to reviewing the wealth of previous research and work in optimization. It offers a
comprehensive look at the historical progression of Bayesian Optimization, highlighting key developments and
milestones. This exploration provides valuable context, showing how we have arrived at the present state where
Bayesian techniques are employed to optimize intricate functions. It underscores the significance of Bayesian
Optimization in solving complex optimization challenges.Chapter 3
Methodology
3.1 Introduction
In this chapter, the report introduces the methodology of Bayesian Optimization and Batch Bayesian Opti-
mization. It delves into the step-by-step process of this potent optimization technique. Describing the essential
concepts and procedures involved provides a clearer understanding of how Bayesian Optimization is employed
sequentially and simultaneously to tackle complex optimization problems. This chapter is a foundational guide
for individuals and researchers interested in applying Bayesian Optimization to address complex optimization
challenges.
3.2 Working Model
Consider the maximization of an unknown function fthat is very costly to evaluate, which can be formu-
lated as follows:-
x∗= arg max
x∈Xf(x)
where Xdenotes the search/decision space of interest and x∗is the global maximum. Fundamentally,
Bayesian optimization follows a systematic approach. It begins by creating a probabilistic model, often called
a surrogate model. This model characterizes a distribution over the objective function, refining its represen-
tation as new data becomes available. Initially, Bayesian optimization establishes a prior distribution over the
function, describing our initial beliefs about it. Then, applying Bayes’ rule calculates the posterior distribution
based on the observed data and the prior. This updated distribution describes our revised understanding of the
unknown objective function. Consequently, Bayesian optimization leverages this posterior distribution to iden-
tify the next data sample. This selection is facilitated by optimizing auxiliary functions known as acquisition
functions within the Bayesian optimization framework.8 Methodology
3.2.1 Restrictions
The field of optimization is both foundational and extensive within mathematics. A set of conditions must
be defined to apply it to specific objectives effectively. One key specification is the focus on the maximiza-
tion form of the problem, in contrast to the more common minimization scenarios. The maximization of a
real-valued function denoted as x∗= arg max
xf(x), can be equivalently framed as the minimization of a
transformed function, represented as:
g(x) =−f(x).
Additionally, it is assumed that the objective function adheres to Lipschitz continuity. This implies the
existence of a constant C(even though the exact value of Cmay be unknown or unspecified.) for which the
following condition holds for all x1, x2∈A:
|f(x1)−f(x2)| ≤C∥x1−x2∥,
Further narrowing the scope, the problem is defined as one of global optimization instead of local optimiza-
tion. In local maximization problems, the objective is to locate a point x∗satisfying the condition:
f(x∗)≥f(x)for all xwithin a distance of ϵfrom x∗.
In cases where −f(x)is convex, any local maximum also qualifies as a global maximum. However, the
optimization problems at hand do not assume that the negation of the objective function is convex.
3.3 Bayesian Optimization
3.3.1 Gaussian Process
A Gaussian Process (GP) can be understood as a collection of random variables where the joint distribution
of any finite subset among them adheres to a consistent Gaussian distribution. Unlike the Gaussian distribution,
which operates over vectors with a mean and covariance matrix, a Gaussian Process extends this concept to
functions. Essentially, a Gaussian Process is entirely defined by its mean function, denoted as m(x), and its
covariance function, denoted as k(x, x 0). This can be concisely expressed as:
f∼GP(m, k)
Here, this notation signifies that the function ffollows a Gaussian Process characterized by the mean function
mand the covariance function k.
The mean and covariance functions of this Gaussian process are defined as follows for i= 1, . . . , n and
i, j= 1, . . . , n respectively:
µi=m(xi) =1
nx2
i3.3 Bayesian Optimization 9
κij=k(xi, xj) = exp
−1
2(xi−xj)2
This Gaussian process is the prior for Bayesian Inference and is independent of training data. The next step
is to update the prior based on the training data, referred to as the posterior.
Letfrepresent the known function values of the training cases, and let f∗be a set of function values
corresponding to the test set inputs X∗. The joint distribution is defined as:

f
f∗
∼ N

µ
µ∗

K K ∗
KT
∗K∗∗


In this context, a shorthand notation is introduced: µ=m(xi), where iranges from 1 to n, representing the
means of the training cases. Similarly, this notation is extended to the test means as µ∗. Regarding covariance,
Kdenotes the covariances within the training set, K∗for the covariances between the training and test sets,
andK∗∗for the covariances within the test set.
Given the knowledge of the training set values f, the focus shifts to the conditional distribution of f∗given
f, which can be succinctly represented as:
f∗|f∼ N 
µ∗+KT
∗K−1(f−µ), K∗∗−KT
∗K−1K∗
From Python experiments, a graph is obtained for the Gaussian process as shown in Fig. 4.1.
3.3.1.1 Choice Of Covariance Function
The selection of a covariance function for a Gaussian Process (GP) is essential, as it governs the smoothness
characteristics of the samples generated from the process. The commonly used squared exponential kernel
exhibits a certain degree of simplicity by treating divergences in all features of input xwith equal impact on
the covariance.
κij=k(xi, xj) = exp
−1
2(xi−xj)2
, i, j = 1, . . . , n
Typically, a better approach involves introducing hyperparameters for different situations. In the case of an
isotropic model, a single hyperparameter θcan be used to regulate the kernel’s bandwidth.
k(xi, xj) = exp
−2
θ2
1∥xi−xj∥2
(3.1)
A comparison graph of the Gaussian process with different timescales is obtained from Python experiments
as shown in Fig 4.2.
The Mat ´ern kernel is an important kernel for Bayesian optimization, allowing greater flexibility in modeling
functions. It is defined as:
k(xi, xj) =1
2ν−1Γ(ν)√
2ν∥xi−xj∥
ρν
Hν−1√
2ν∥xi−xj∥
ρ
, (3.2)10 Methodology
where νis the smoothness parameter, ρis the length scale, Γ(·)is the Gamma function, and Hν−1(·)is the
Bessel function of order ν−1.
Asνapproaches infinity ( ν→ ∞ ), the Mat ´ern kernel converges to the squared exponential kernel. When
ν= 0.5, it simplifies to the unsquared exponential kernel.
3.3.2 Acquisition Function
The role of the acquisition function in Bayesian optimization is to guide the search for the optimum. It
is pivotal in determining the next point to evaluate the function, effectively influencing the decision-making
process. The goal is to sample the objective function fat the point arg max xu(x|D), where u(·)serves as the
symbol representing an acquisition function. This strategic approach ensures that the optimization process is
directed towards areas of interest and high potential for improvement.
3.3.2.1 Probability of improvement
The early work of Kushner [4] suggested maximizing the probability of improvement over the function
f(x+), where x+= arg max xi∈x1:tf(xi). Thus, the Probability of Improvement (PI) is given by:
PI(x) =P(f(x)≥f(x+)) = Φµ(x)−f(x+)
σ(x)
,
where Φ(·)is the normal cumulative distribution function.
The drawback of this formulation is its focus on pure exploitation. It tends to favor points that have a high
probability of being only slightly better than f(x+), even if there are points with larger potential gains and less
certainty. To mitigate this, a modification introduces a trade-off parameter λ≥0.The choice of λis typically
up to the user:
PI(x) =P(f(x)≥f(x+) +λ) = Φµ(x)−f(x+)−λ
σ(x)
.
The total area of the shaded region in Fig. 3.1 represents the CDF of the plot, which inturn represents the
probability of improvement. The probability of improvement acquisition function plotted based on a Gaussian
process is depicted in Fig. 4.3.
3.3.2.2 Expected Improvement
Estimating the potential improvement from evaluating the objective function at a specific point compared
to the current best solution involves considering the probability of improvement and the magnitude of potential
improvement. A more effective acquisition function would aim to minimize the expected deviation from the
actual maximum f(x∗)when selecting a new trial point:
xt+1= arg min
xE 
∥kft+1(x)−f(x∗)∥ |D1:t
= arg min
xZ
∥kft+1(x)−f(x∗)∥P(ft+1|D1:t)d ft+1,3.3 Bayesian Optimization 11
Figure 3.1: The region of probable improvement.
where D1:trepresents the observed data up to time t.
Mockus proposes a more practical approach to maximize the expected improvement [5]. The improvement
function I(x)is defined as:
I(x) = max {0, ft+1(x)−f(x+)},
where f(x+)is the best value known thus far. The new query point is then found by maximizing the expected
improvement:
x= arg max
xE 
max{0, ft+1(x)−f(x+)} |Dt
.
The expected improvement EI(x)can be calculated analytically and is given by:
EI(x) =

(µ(x)−f(x∗))Φ
µ(x)−f(x∗)
σ(x)
+σ(x)ϕ
µ(x)−f(x∗)
σ(x)
,ifσ(x)>0,
0, ifσ(x) = 0 ,
where Φ(·)andϕ(·)are the cumulative distribution function and probability density function of the standard
normal distribution, respectively.
3.3.2.3 Knowledge Gradient
However, the Expected Improvement (EI) explores the initial best point before the algorithm searches more
globally. This is because EI values are high only for points close to the current best point.
An idea closely related to EI is the Knowledge Gradient (KG) [6], which aims to maximize the expected
incremental value of a measurement. Unlike EI, KG does not rely on the optimum obtained so far. Let µn
denote the mean of the posterior distribution after nsamples. If we take one more sample, a new posterior
distribution with posterior mean µn+1will be generated. Hence, the KG is formulated as:
KG(x) =En[max( µn+1)−max( µn)],12 Methodology
where En[·] := E[·|X, y]indicates the conditional expectation concerning what is known after the first n
measurements.
3.3.2.4 Upper Confidence Bound
The confidence bound criteria, known as the Upper Confidence Bound (UCB) [7] for maximization prob-
lems and the Lower Confidence Bound (LCB) for minimization problems, are used to achieve optimal regret
in the multi-armed bandit community. They combine uncertainty and expected reward. UCB is calculated as:
UCB (x) =µ(x) +βσ(x),
where β >0governs the trade-off between exploitation and exploration. In the case of LCB, there is a minus
sign in front of the βterm.
3.3.2.5 Lipschitzian Optimization
Lipschitzian optimization is a global optimization technique that can be applied effectively under certain
restrictions. Given the vastness of the optimization field, only some methods can perform the entire procedure.
Lipschitzian optimization [1] assumes knowledge of the Lipschitzian constant, denoted as K, and satisfies
the following equation:
|f(x)−f(x′)| ≤K∥x−x′∥
This assumption allows us to establish a lower bound on the function within any closed interval whose
endpoints have been evaluated. By substituting aandbforx′in the above equation, we obtain the following
two inequalities:
f(x)≥f(a)−K(x−a)
f(x)≥f(b) +K(x−b)
These inequalities correspond to two lines with slopes −Kand+K. The function must lie above the V-
shape formed by the intersection of these two lines. Therefore, the lowest value that f(x)can attain is at the
bottom of the V curve.
Denoting this point as X(a, b, f, K )and the corresponding lower bound of fasB(a, b, f, K ), we have:
X(a, b, f, K ) =a+b
2+f(a)−f(b)
2K
B(a, b, f, K ) =f(a) +f(b)
2−K(b−a)3.4 Batch Bayesain Optimization 13
Figure 3.2: Computing the Lipschitzian bound for an interval [1]
The optimization process begins with the evaluation of the function at the endpoints. Subsequently, we
evaluate the function at x1=X(l, u, f, K ). This step divides the search space into two intervals: (l, x1)and
(x1, u). We then determine which of these intervals has the lowest B-value.
The interval with the lowest B-value is [x1, u], so we evaluate the function at x3=X(x1, u, f, K ). The
next sampled point is the minimum of this piecewise linear approximation.
3.4 Batch Bayesain Optimization
Bayesian Optimization typically limits parameter space exploration to sequential processes, there is of-
ten a desire to concurrently propose batches of parameter values, particularly in the presence of large parallel
processing capabilities. However, implementing batch methods requires modeling the interaction among eval-
uations within the batch, which can be costly in complex scenarios. In addressing this challenge, a highly ef-
fective heuristic is introduced on an estimate of the function’s Lipschitz constant, focusing on the crucial aspect
of local repulsion, with minimal computational overhead. To facilitate simultaneous exploration,a penalized
acquisition function to gather batches of points, aiming to minimize non-parallelizable computational effort.
The resulting algorithm exhibits impressive runtime performance, comparing favorably with more intricate al-
ternatives. Batch Bayesian Optimization introduces a promising solution for efficient parameter exploration,
particularly valuable in scenarios with substantial parallel processing resources.
3.4.1 Local Penalizer
A function ϕ(x;xj), referred to as a local penalizer, is introduced to modify the behavior of a generic
acquisition function α(x)at a specific point xjwithin the set X. This function plays a role in local adjustments
around xj.
Characteristics of Local Penalizer:14 Methodology
•ϕ(x;xj)must be differentiable.
• The values of ϕ(x;xj)are restricted to the interval 0≤ϕ(x;xj)≤1.
• The function ϕ(x;xj)is expected to increase as a function of the absolute difference |x−xj|.
During optimization, the traditional marginalization step is replaced by directly penalizing α(x;It,k−1)
around its most recent maximum. The maximization-penalization strategy selects xt,kas follows:
xt,k= arg max
x∈X
g(α(x;It,0))k−1Y
j=1ϕ(x;xt,j)

Here, ϕ(x;xt,j)represents local penalizers centered at xt,j, andg:R→R+is a differentiable transforma-
tion of α(x). The transformation ensures the positivity of α(x)without changing the locations of its extrema.
Specifically, g(z) =zifα(x)is already positive, and g(z) = ln(1 + ez)elsewhere.
The role of a local penalizer is to smoothly decrease the value of the acquisition function in the neighbor-
hood of xj. An effective local penalizer at xjshould reflect the belief about the distance from xjtoxM. If
xMis far from xj, a broad ϕ(x;xj)will discard a large portion of X. Conversely, if xMandxjare close,
the penalization of α(x)should be minimized, encouraging the collection of samples in a close neighborhood.
The local penalization captures the dynamics of the acquisition function under a sequential policy, where the
modes of the acquisition functions correspond to regions with large uncertainty. The functions ϕ(x;xj)act as
surrogates for these neighborhoods.
3.4.1.1 Choosing Local Penalizers
Local penalizing functions, denoted as ϕ(x;xj), play a crucial role in capturing the current belief about the
distance from batch locations to the maximum point xM.
LetMrepresent the maximum function value in the set X, andLbe a valid Lipschitz constant. Consider a
ball defined by:
Brj(xj) ={x∈X:∥xj−x∥ ≤rj}
where the radius rjis given by:
rj=M−f(xj)
L
For simplicity, assume rjis denoted as r(xj)for the radius of the ball around xj. Iffrepresents the true
optimization objective, then xMis not within Brj(xj); otherwise, the Lipschitz condition would be violated.
The size of Brj(xj)depends on L,M, and the value of fatxj. Both large variability in f(large L) and the
proximity of f(xj)to the optimum Mresult in the shrinking3.5 Augmenting the Datapoints 15
3.4.2 Selecting Lipschitzian Constant ( L) and Maxima ( M)
The values of MandLare typically unknown. To estimate M, one can use ˆM= max Xµn(x)or, for a
rougher approximation, ˆM= max y∈range (f)y.
For determining L, especially in the context of Bayesian optimization penalization, small but feasible values
are preferred, as they lead to large exclusion zones and a more efficient search. If access to the true objective f
is available, one can demonstrate that Lr= max x∈X|rf(x)|is a valid Lipschitz constant. Note that Lris the
smallest value of Lsatisfying the Lipschitz condition as x1→x2.
To approximate Lr, assuming fis a draw from a Gaussian Process with at least a twice-differentiable kernel
k, the gradient of fatx∗is distributed as a multivariate Gaussian rf(x∗)|X, y, x∗∼ N(¯µr(x∗), σ2
r(x∗))with
mean vector
¯µr(x∗) =∂Kn
∂x∗(˜Kn)−1y,
and covariance matrix
σ2
r(x∗) =∂2k(x∗, x∗)
∂x∗∂x∗−∂Kn
∂x∗(˜Kn)−1∂Kn
∂x∗,
where ˜Kn=Kn+σ2I. We choose
ˆLGP-LCA = max
X|¯µr(x∗)|
and refer to this as the Gaussian Process Lipschitz Constant Approximation criterion (GP-LCA). Note that
this definition of ˆLGP-LCA disregards the variance of the gradient, which could be utilized to identify candidate
points for improving the approximation of Lrin a Bayesian optimization fashion.
3.5 Augmenting the Datapoints
After identifying the extremum point using the acquisition function, the corresponding y-coordinate of the
obtained data point is determined. Subsequently, this data point is incorporated into the existing set of obser-
vations, and the Gaussian process model is updated accordingly. This iterative process continues until it meets
the predefined threshold value. Optimization of a black box function obtained through Python experimentation
is shown in Fig. 4.6.
3.6 Summary
The methodology of Bayesian optimization involves a structured sequence of steps to find the optimal
solution efficiently. First, it begins by building a probabilistic model, often called a surrogate model, using
a Gaussian Process (GP). This surrogate model serves as a representation of the objective function. Next,
an acquisition function is defined as a guide in the search process. This acquisition function helps select the
next evaluation point within the search space by balancing exploring uncharted areas and exploiting promising16 Methodology
regions. The optimization of the acquisition function is a critical step. It identifies the point in the search space
expected to yield the most valuable information. The objective function is evaluated at this chosen point, and
its corresponding value is obtained.
Batch Bayesian Optimization outlines the construction of penalizing functions within the context of Bayesian
optimization. It introduces the concept of local penalizers, which integrate beliefs regarding the distance from
batch locations to the global maximum. The proposed approach advocates for a maximization-penalization
strategy as a substitute for the traditional maximization-marginalization loop. The chapter details the formu-
lation of the local penalizer function and presents an approximation for the Lipschitz constant. The primary
objective is to improve the efficiency of Batch Bayesian optimization by narrowing down the search space
based on current beliefs about the global maximum’s location.
The newly acquired data point is incorporated into the existing set of observations to refine the surrogate
model continually. This updating process ensures that the surrogate model becomes more accurate over time.
The entire methodology operates iteratively until a predefined stopping criterion is met.Chapter 4
Results and Discussions
4.1 Introduction
In the preceding chapter, the methodology for Bayesian optimization was discussed. The current chapter
transitions to examining the results obtained through Python experiments. These experiments offer practical
insights into the performance of Bayesian optimization in real-world contexts. The analysis of these results
allows for an understanding of the effectiveness and applicability of Bayesian optimization in complex opti-
mization tasks.
4.2 Results
4.2.1 Bayesian Optimization
Bayesian Optimization, a robust optimization technique, has been applied to the defined search space to
uncover optimal solutions. Developed a Gaussian process with and without the package and explored the
performance of various acquisition functions to guide the optimization process. These are the results obtained
after implementing the coding procedure of Bayesian Optimization.
4.2.1.1 Gaussian Process
A Gaussian process has been constructed, which is essentially a function derived from the mean and covari-
ance of the data points. In this construction, the mean function is assumed to be zero, while the Radial Basis
Function (RBF) kernel serves as the covariance function.18 Results and Discussions
Figure 4.1: Gaussian Process
4.2.1.2 Gaussian Process using Different Lengthscales
Gaussian processes can be compared by varying the lengthscale ( l) of the kernel. The lengthscale parameter
controls the “smoothness” of the Gaussian process. This comparison compares different lengthscale values
such as: l= [0.25,0.5,1.0,2.0,4.0].
Figure 4.2: Effect of different Lengthscales using a Gaussian Process
4.2.1.3 Acquisition Function
The acquisition function, which directs the Bayesian optimization process, is formulated based on the
Probability of Improvement (PI), Expected Improvement (EI), and Upper Confidence Bound (UCB). This
involves utilizing the input values from the dataset to determine the associated Ycoordinate, as described by
the following Eqn 3. The dotted red line indicates the peak of the acquisition function, i.e., the next point to be4.2 Results 19
evaluated.
Figure 4.3: Probability Of Improvement
Figure 4.4: Expected Improvement
4.2.1.4 Bayesian Optimization illustration
An overview of Bayesian Optimization as a unified process is provided by highlighting how its constituent
components work together.
4.2.2 Batch Bayesian Optimization
Batch Bayesian optimization is a powerful technique for optimizing complex and computationally expen-
sive objective functions. It efficiently explores the search space by considering multiple configurations simul-
taneously, using probabilistic models, Lipschitz constant estimation, and a penalized acquisition function. This
approach is particularly beneficial in scenarios where evaluating the objective function is resource-intensive.20 Results and Discussions
Figure 4.5: Upper Confidence Bound
Figure 4.6: Bayesian Optimization
4.2.3 Maximum Probability Of Improvement
The Maximum Probability of Improvement (MPI) acquisition function seeks the point with the highest
probability of improving upon the current best observed value in Bayesian optimization
4.2.3.1 Local Penalization
The below figure represent the posterior mean , posterior standard deviation and the acquisition function
plot when the function is set to MPI and evaluator type is Local Penalization.
4.2.3.2 Without Local Penalization
The below figure represent the posterior mean , posterior standard deviation and the acquisition function
plot when the function is set to MPI and evaluator type is discarded.4.2 Results 21
Figure 4.7: Maximum Probability of Improvement via Local Penalization
Figure 4.8: Maximum Probability of Improvement
4.2.4 Expectation Improvement
4.2.4.1 Local Penalization
The below figure represent the posterior mean , posterior standard deviation and the acquisition function
plot when the function is set to EI and evaluator type is Local Penalization.
4.2.4.2 Without Local Penalization
The below figure represent the posterior mean , posterior standard deviation and the acquisition function
plot when the function is set to EI and evaluator type is discarded.
4.2.5 Convergence Plot
The convergence plot visually depicts the optimization process over iterations, showcasing the change in
the objective function’s values over time.22 Results and Discussions
Figure 4.9: Expectation Improvement via Local Penalization
Figure 4.10: Expectation Improvement
4.2.5.1 Maximum Probability of Improvement
The below comparison shows that Local Penalization helps to converge to a particular value much faster
when compared without local penalization in case of MPI acquisition function
4.2.5.2 Expectation Improvement
The below comparison shows that Local Penalization helps to converge to a particular value much faster
when compared without local penalization in case of EI acquisition function.
4.3 Summary
The results obtained from the Bayesian Optimization experiments sequentially and simultaneously provide
valuable insights into the effectiveness of this optimization technique. The analysis focused on using different
kernels to build a Gaussian process via different lengthscales and various acquisition functions .4.3 Summary 23
Figure 4.11: Convergence plot of MPI with
Local Penalization
Figure 4.12: Convergence plot of MPI with-
out Local Penalization
Figure 4.13: Comparison of Convergence Plots
Figure 4.14: Convergence plot of EI with
Local Penalization
Figure 4.15: Convergence plot of EI without
Local Penalization
Figure 4.16: Comparison of Convergence PlotsChapter 5
Conclusions and Future Work
5.1 Introduction
The previous chapter describes the results obtained by doing the Python experimentation. This chapter
mainly focuses on concluding the report and showcasing the future development scope.
5.2 Conclusion
In summary, Bayesian Optimization has showcased the effectiveness of this optimization approach in nav-
igating complex search spaces and pinpointing optimal solutions. By examining various acquisition func-
tions like Expected Improvement (EI), Upper Confidence Bound (UCB), Probability of Improvement (PI), and
Knowledge Gradient (KG), we have gained valuable insights into how they perform.
Bayesian Optimization has proven particularly useful when the objective function is challenging to describe
analytically or demands significant computational resources to assess. It balances exploring new areas and
exploiting promising ones, efficiently guiding the search while conserving valuable resources.
The results emphasize that the choice of the acquisition function plays a crucial role in the optimization
process. Each function has its strengths depending on the nature of the problem. These findings offer practical
guidance to professionals facing real-world optimization challenges.
Moreover, Bayesian Optimization’s flexibility and reliability make it a valuable tool across various domains,
such as machine learning, engineering, and scientific research.26 Conclusions and Future Work
5.3 Future Work
In the future, it would be interesting to explore how Bayesian Optimization can be applied to tackle high-
dimensional problems. These are situations where numerous factors need consideration, such as fine-tuning
complex machine learning models with a multitude of settings. While Bayesian Optimization has proven effec-
tive in optimizing problems with a few factors, adapting it to work seamlessly in scenarios with many factors
remains a significant challenge. One avenue worth exploring is the integration of Multi-Objective Optimiza-
tion principles to enhance the algorithm’s ability to handle diverse and complex optimization objectives within
high-dimensional spacesReferences
[1] D. R. Jones, C. D. Perttunen, and B. E. Stuckman, “Lipschitzian optimization without the lipschitz con-
stant,” Journal of optimization Theory and Applications , vol. 79, pp. 157–181, 1993.
[2] C. E. Rasmussen, “Gaussian processes in machine learning,” in Summer school on machine learning .
Springer, 2003, pp. 63–71.
[3] H. Kushner, “A versatile stochastic model of a function of unknown and time varying form,” Journal of
Mathematical Analysis and Applications , vol. 5, no. 1, pp. 150–167, 1962.
[4] H. J. Kushner, “A new method of locating the maximum point of an arbitrary multipeak curve in the
presence of noise,” 1964.
[5] J. Mo ˇckus, “On bayesian methods for seeking the extremum,” in Optimization Techniques IFIP Technical
Conference: Novosibirsk, July 1–7, 1974 . Springer, 1975, pp. 400–404.
[6] P. I. Frazier, W. B. Powell, and S. Dayanik, “A knowledge-gradient policy for sequential information
collection,” SIAM Journal on Control and Optimization , vol. 47, no. 5, pp. 2410–2439, 2008.
[7] N. Srinivas, A. Krause, S. M. Kakade, and M. Seeger, “Gaussian process optimization in the bandit
setting: No regret and experimental design,” arXiv preprint arXiv:0912.3995 , 2009.
[8] B. O. Shubert, “A sequential method seeking the global maximum of a function,” SIAM Journal on Nu-
merical Analysis , vol. 9, no. 3, pp. 379–388, 1972.
[9] M. V olpp, L. P. Fr ¨ohlich, K. Fischer, A. Doerr, S. Falkner, F. Hutter, and C. Daniel, “Meta-learning
acquisition functions for transfer learning in bayesian optimization,” arXiv preprint arXiv:1904.02642 ,
2019.
[10] R. Caruana, “Multitask learning,” Machine learning , vol. 28, pp. 41–75, 1997.
[11] K. Swersky, J. Snoek, and R. P. Adams, “Multi-task bayesian optimization,” Advances in neural informa-
tion processing systems , vol. 26, 2013.28 REFERENCES
[12] J. Chen, F. Luo, and Z. Wang, “Dynamic multi-objective ensemble of acquisition functions in batch
bayesian optimization,” in Proceedings of the Genetic and Evolutionary Computation Conference Com-
panion , 2022, pp. 479–482.